{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-SNE plot generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE, SpectralEmbedding\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SMALL_SIZE = 14\n",
    "MEDIUM_SIZE = 18\n",
    "BIGGER_SIZE = 22\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_df = pd.read_csv('../wandb_results/vgg_cifar10_wandb_export.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['epochs', 'batch_size', 'learning_rate', 'adam_epsilon']\n",
    "vgg_X = vgg_df[features].values\n",
    "vgg_y = vgg_df['accuracy_diff'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_X_embedded = SpectralEmbedding(n_components=2).fit_transform(vgg_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "img = plt.scatter(vgg_X_embedded[:, 0],vgg_X_embedded[:, 1] , c= vgg_y, cmap=\"viridis\")\n",
    "fig.colorbar(img, orientation=\"vertical\", label=\"Accuracy Differnece\")\n",
    "ax.set_xlabel('Spectral Component 1')\n",
    "ax.set_ylabel('Spectral Component 2')\n",
    "plt.savefig('vgg_spectral_params.png', bbox_inches=\"tight\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_max = np.max([np.max(vgg_mi), np.max(dense_mi), np.max(resnet_mi)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.12358599, 0.04304035, 0.15327897])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_mi = mutual_info_regression(vgg_X, vgg_y)\n",
    "# vgg_mi /= np.max(vgg_mi)\n",
    "vgg_mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.68144608, 1.        , 0.25444389, 0.42359379])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_df = pd.read_csv('../wandb_results/resnet_cifar10_wandb_export.csv')\n",
    "features = ['epochs', 'batch_size', 'learning_rate', 'adam_epsilon']\n",
    "resnet_X = resnet_df[features].values\n",
    "resnet_y = resnet_df['accuracy_diff'].values\n",
    "resnet_mi = mutual_info_regression(resnet_X, resnet_y)\n",
    "resnet_mi /= np.max(resnet_mi)\n",
    "resnet_mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.12302519, 0.24898544, 0.12779857])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_df = pd.read_csv('../wandb_results/densenet_cifar10_wandb_export.csv')\n",
    "features = ['epochs', 'batch_size', 'learning_rate', 'adam_epsilon']\n",
    "dense_X = dense_df[features].values\n",
    "dense_y = dense_df['accuracy_diff'].values\n",
    "dense_mi = mutual_info_regression(dense_X, dense_y)\n",
    "dense_mi /= np.max(dense_mi)\n",
    "dense_mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(vgg_mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_df = pd.DataFrame(columns=['Compared Stat', 'MI', 'Model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_plot = [\"Epochs\", \"Batch Size\", \"Learning Rate\", \"Adam Epsilon\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    mi_df = mi_df.append({'MI':vgg_mi[i], 'Compared Stat': features_plot[i], 'Model':'VGG'}, ignore_index=True)\n",
    "    mi_df = mi_df.append({'MI':resnet_mi[i], 'Compared Stat': features_plot[i], 'Model':'ResNet'}, ignore_index=True)\n",
    "    mi_df = mi_df.append({'MI':dense_mi[i], 'Compared Stat': features_plot[i], 'Model':'DenseNet'}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(x=\"Compared Stat\", y=\"MI\", hue=\"Model\", data=mi_df, palette=\"viridis\")\n",
    "plt.ylabel(\"Normalized Mutual Information\")\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(11, 8)\n",
    "plt.tight_layout()\n",
    "plt.savefig('totalmax_normalized_mutual_info_sklearn.jpeg', dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from scipy.special import gamma,psi\n",
    "from scipy import ndimage\n",
    "from scipy.linalg import det\n",
    "from numpy import pi\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "EPS = np.finfo(float).eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_information_2d(x, y, sigma=1, normalized=False):\n",
    "    \"\"\"\n",
    "    Computes (normalized) mutual information between two 1D variate from a\n",
    "    joint histogram.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : 1D array\n",
    "        first variable\n",
    "    y : 1D array\n",
    "        second variable\n",
    "    sigma: float\n",
    "        sigma for Gaussian smoothing of the joint histogram\n",
    "    Returns\n",
    "    -------\n",
    "    nmi: float\n",
    "        the computed similariy measure\n",
    "    \"\"\"\n",
    "    bins = (256, 256)\n",
    "\n",
    "    jh = np.histogram2d(x, y, bins=bins)[0]\n",
    "\n",
    "    # smooth the jh with a gaussian filter of given sigma\n",
    "    ndimage.gaussian_filter(jh, sigma=sigma, mode='constant',\n",
    "                                 output=jh)\n",
    "\n",
    "    # compute marginal histograms\n",
    "    jh = jh + EPS\n",
    "    sh = np.sum(jh)\n",
    "    jh = jh / sh\n",
    "    s1 = np.sum(jh, axis=0).reshape((-1, jh.shape[0]))\n",
    "    s2 = np.sum(jh, axis=1).reshape((jh.shape[1], -1))\n",
    "\n",
    "    # Normalised Mutual Information of:\n",
    "    # Studholme,  jhill & jhawkes (1998).\n",
    "    # \"A normalized entropy measure of 3-D medical image alignment\".\n",
    "    # in Proc. Medical Imaging 1998, vol. 3338, San Diego, CA, pp. 132-143.\n",
    "    if normalized:\n",
    "        mi = ((np.sum(s1 * np.log(s1)) + np.sum(s2 * np.log(s2)))\n",
    "                / np.sum(jh * np.log(jh))) - 1\n",
    "    else:\n",
    "        mi = ( np.sum(jh * np.log(jh)) - np.sum(s1 * np.log(s1))\n",
    "               - np.sum(s2 * np.log(s2)))\n",
    "\n",
    "    return mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4249600116580297"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutual_information_2d(vgg_df['adam_epsilon'], np.array(vgg_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
